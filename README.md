# unreasonable-llama

Yet another Python API for llama.cpp server

For now, i'm targeting minimal support necessary for `/completion` endpoint.
Maybe i'll extend this lib in the future.
